\chapter{Identifying AER with NLP and AI techniques}
\label{cha:nlp_and_ai}

Another studied methodology for finding AER issues is related to the use of AI models powered by NLP techniques. We will evaluate the implementation of different static and dynamic word embedding models to extract and define a set of keywords present in GitHub commits of a set of Android projects. With the set of keywords used in the related work section, we will extract more keywords found in a large set of GitHub commits of different Android projects. We measured the cosine similarity average and the cosine similarity between each keyword to define which is the best model to define new keywords that could indicate an AER issue in any GitHub commit \cite{codereviewer}. Additionally, we will train an AI model to find new keywords and make a comparison with the static word embedding models. This model is CodeReviewer, which is based on the transformer architecture. With this model, it is possible to find more similar words due to the number of dimensions that implement its tokenizer component. Finally,  we define a testing stage with manual classification of a representative set of commits for the case of the words generated by static word embedding models. For dynamic word embedding models, we will implement an AI agent with the OpenAI library to evaluate the effectiveness of the trained CodeReviewer model. The main objective of this is to explore and evaluate this methodology for AER issues identification in Android projects.

\section{Methodology Definition}
With the proposed tools and approaches for the implementation of this methodology, we will define a complete workflow to extract and build the commits dataset. After that, we processed the corpus of the commit with NLP fundamentals to find the most similar keywords based on the found keywords that could indicate an AER issue in a code fragment of any versioning platform commit. We used the cosine similarity metric to find the most similar keywords. Those keywords were added to the initial set to find new commits in the extracted commits dataset. Finally, we implemented manual tagging and the use of an AI Agent with a customized prompt to make the comparison of the results between the implemented models: static and dynamic word embedding models. 

\subsection{Commits Extraction}
The first process is the extraction of a set of commits to evaluate and identify AER issues. We selected a set of platforms with customized filter criteria to get a set of 50 Android applications. With the given set of Android applications, we used repository mining techniques to extract relevant information from each commit of each repository in the set of Android applications. We built a dataset with the set of commits and implemented different word embedding models to find potential keywords that could indicate an AER issue in any GitHub commit of any Android project. We made a comparison between the results given by static and dynamic word embedding models. We proposed the use of an AI model named CodeReviewer. We trained and extracted the embedding of each keyword and made a comparison between all the words of the corpus of GitHub commits based on the cosine similarity metric definition.

\subsubsection{Applications selections}
We used two platforms to build the Android application set: GHS from SEART and FDroid \cite{seart,fdroid}. GHS is a repository mining platform of GitHub repositories developed by SEART. We implemented different filters to get some Android applications to the AER issues evaluation. The filters were based on the number of commits (between 1000 and more than 20000 commits), the main programming language as Kotlin, and the date of the last commit. These filters were implemented to get enough information to analyze the presented AER issues in code fragments implemented with the Kotlin programming language.
The second used platform was FDroid. FDroid is an open-source marketplace with Android applications. FDroid provides some important information about every Android project, like GitHub repository URL and the software license. We randomly extracted s subset of Android applications to add to the previous set of applications extracted from GHS. Summarizing, we extracted a set of 50 Android applications to process their commits to make an NLP processing and find new potential keywords related to the AER phenomenon.

There are some practices and techniques for repository mining. Repository mining allows the finding of relevant information from any source code repository in any versioning platform like GitHub, GitLab, BitBucket, etc. Some tools and libraries have been developed for this purpose. The selected library for this is the PyDriller library \cite{pydriller}.  PyDriller can extract relevant information from each commit, like project name, commit hash, modified source code, etc. We define a common structure to build the commits dataset. This is shown in Table xxxx.  With the defined structure, we implement a Python program to extract from the GitHub repositories of each Android project. The execution of the program generated a dataset of more than 470000 GitHub commits. The commits were filtered if each one contains or not one of the keywords defined in the previous steps.

%%% TODO: AGREGAR TABLA DE DATASET

\subsection{Use of Word Embedding Models}
With the generated dataset of commits. It is possible to explore some alternatives based on NLP techniques. One of them is the use of Word Embedding models. These models help to get a numerical representation of the words in specific or dynamic contexts. Numerical representation of words helps in computer processing and metrics building. With the two different types of Word Embedding models, we explored the definition of the most similar keywords from the previous set. In the workflow, we defined the use of two approaches to identify new AER keywords: using static and dynamic Word Embedding models.

\subsubsection{Static Word Embedding Models}
Static Word Embedding models are limited by their training context. We considered the well-known Word Embedding models for text processing, and one Word Embedding trained with a large set of Stack Overflow posts, named the SO model. We implemented NLP techniques like lemmatization and stop word removal, and used three static Word Embedding models: Glove, Word2Vec, and the SO model. We calculate the cosine similarity average to get the top 10 most similar words of each Word Embedding model. We realized the comparison between each Word Embedding model according to the average cosine similarity. Another approach used was to calculate the top 10 most similar words for each keyword of the previous set. However, a large set of words was selected, and some of them were not related to the technological context and the main objective of the methodology. We defined an embedding dimension of 200



\subsubsection{Dynamic Word Embedding Models}
Due to the limited resources of static Word Embedding models, it is necessary to explore additional alternatives to get an improvement with respect to the context of those models. For this, we considered the use of AI models that are trained for code classification and generation. Models like CodeBERT and T5 are small and effective models to classify and generate code based on different training strategies, like code masking, to predict the right keyword in any code fragment \cite{codebert,t5}.  


\subsection{Testing the models}



\section{Methodology Implementation}


\subsection{Commits Extraction}

\subsection{Word Embedding Models Results}

\subsubsection{Static Word Embedding Models}

\subsubsection{Dynamic Word Embedding Models}



\section{Conclusions}


